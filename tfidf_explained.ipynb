{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF: different results from different definitions\n",
    "by MAS, 2018\n",
    "\n",
    "Last year, I wrote a [Python script](https://github.com/mas16/keywords) to scrape text from the [NIH database](https://www.ncbi.nlm.nih.gov/pubmed/) of published research and classify different researchers by the words that appeared most frequently across their publications. The script calculates a statistic called the **term frequency** (tf) which is the number of times a given word appears in a given text. Since I wasn't too careful about style back then, my code is a bit clunky so I decided to see if I could streamline things with scikit-learn (```sklearn```).\n",
    "\n",
    "I hadn’t used ```sklearn``` for text analysis before so I started by looking for a good tutorial. After some googling, I found Chris Perone’s awesome [post](http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/) about ```sklearn```’s text feature extraction methods. He covers the tf which is what I was originally interested in as well as an additional statistic known as the **inverse document frequency** (idf). The product of the tf and idf (tf-idf) is a good reporter for how important a word is across *many* texts so I thought it’d be useful to learn about it. \n",
    "\n",
    "I worked through the tutorial (more than once to make sure I was doing it correctly) and was surprised that I couldn’t reproduce his results. This may have been because the post is 8 years old and ```sklearn``` has changed its implementation of things. **Regardless, after some troubleshooting, I found out that ```sklearn``` defines the idf a little bit differently than what is described elsewhere.** \n",
    "\n",
    "If you are not familiar with the tf and idf, I’d highly recommend you check out Chris’ post first. Wikipedia also has a pretty good [description](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) with some examples.\n",
    "\n",
    "Let’s start with Chris’ example and work through what ```sklearn``` does for us. \n",
    "\n",
    "First, define the training and test sets that Chris provides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN SET\n",
    "\n",
    "# d1: the sky is blue\n",
    "# d2: the sun is bright\n",
    "\n",
    "train_set = [\"The sky is blue.\", \"The sun is bright.\"]\n",
    "\n",
    "# TEST SET\n",
    "\n",
    "# d3: The sun in the sky is bright\n",
    "# d4: We can see the shining sun, the bright sun\n",
    "\n",
    "test_set = [\"The sun in the sky is bright.\",\n",
    "            \"We can see the shining sun, the bright sun.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the training set is to define a list of key words (vocabulary) that we will look for in the test set. Once we have the words, we can count them and determine the tf for each. Words like “the” and “is” will be ignored since they are likely to appear all over the place and usually hold little information content. We can use ```sklearn``` to construct the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sky': 2, 'blue': 0, 'sun': 3, 'bright': 1}\n"
     ]
    }
   ],
   "source": [
    "# import CountVectorizer from sklearn \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# make instance of CountVectorizer called 'vectorizer'\n",
    "# add stop_words='english' argument to ignore trivial words\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# create the vocabulary\n",
    "# the vocabulary is a python dictionary\n",
    "# where the keys are the terms and the values are the indices\n",
    "# corresponding to the terms' element after mapping to a vsm\n",
    "\n",
    "vectorizer.fit_transform(train_set)\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```stop_words``` argument passed to ```CountVectorizer``` eliminates trivial words like \"the\" and \"is.\" To keep those words in the analysis, just don't pass ```stop_words```.\n",
    "\n",
    "As you can see from the code block above, the vocabulary is returned as a Python dictionary.\n",
    "\n",
    "The keys are the non-trivial words from the training set that ```sklearn``` identified. The values are the indices for those words in the vector space that the text has been mapped to. This might look a little funny because the order is scrambled. If you want to view the vocabulary in the order that the words appear, you can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blue', 'bright', 'sky', 'sun']\n"
     ]
    }
   ],
   "source": [
    "# to get the words in order do: vectorizer.get_feature_names()\n",
    "# order here refers to the order in which the terms appeared in the text\n",
    "\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let’s create the vector space for the test set and get the tfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [0 1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "# make a sparse matrix using transform method\n",
    "# the matrix will contain the tf in the element position corresponding\n",
    "# to the values listed in the vocabulary dictionary\n",
    "\n",
    "smatrix = vectorizer.transform(test_set)\n",
    "\n",
    "# use .todense() to print in matrix format not coordinate format\n",
    "\n",
    "print(smatrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two rows are for the two documents in the test set, ```d1``` and ```d2``` respectively. The element with index 0 is the number of times the word ‘blue’ appears, the element with index 1 is the number of times the word ‘bright’ appears, the element with index 2 is the number of times the word ‘sky’ appears, and the element with index 3 is the number of times the word ‘sun’ appears. **In other words, these are the tfs of the words from our vocabulary.** \n",
    "\n",
    "At first blush, this might look different from the result Chris posted but the only real difference is the indexing of the words. All of the tf values are the same.\n",
    "\n",
    "Now to move on to the complicated part: calculating the idf. So the idf equation that is listed on Chris’ post is the textbook definition:\n",
    "\n",
    "$ \\Large { idf(t,D) = log \\frac{D}{1+\\{ d \\in D  :  t \\in d\\}} }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FYI Chris uses a log base e (ln) whereas wikipedia suggests using log base 10. \n",
    "\n",
    "What this equation is saying is that the idf value is determined by two parameters: the number of times a given word appears (t) and the total number of documents (D). The idf is then calculated as the log of the total number of documents (D) divided by 1 plus the number of documents (d) within D that contain the word (t).\n",
    "\n",
    "Based on the comments on Chris' post, there seems to be a bit of confusion about the denominator term. Chris states that it is the number of documents that contain the word. A few people commented that the denominator was the number of times the word appeared across all documents. From my research, the former definition is correct.\n",
    "\n",
    "Given the above information, we would expect to see the following results for the idf calculation:\n",
    "\n",
    "  > **Blue**: $ln (2/(1+0)) = 0.693$\n",
    "\n",
    "  > **Bright**: $ln (2/(1+2)) = -0.405$\n",
    "\n",
    "  > **Sky**: $ln (2/(1+1)) = 0$\n",
    "\n",
    "  > **Sun**: $ln (2/(1+2)) = -0.405$\n",
    "  \n",
    " Which is what Chris reports. Now multiplying the idf values by the tf values to get the td-idf values should yield: \n",
    "\n",
    "$$\n",
    "\\large{\n",
    "\\begin{bmatrix} \n",
    "0 & -0.405 & 0 & -0.405 \\\\\n",
    "0 & -0.405 & 0 & -0.810 \n",
    "\\end{bmatrix}\n",
    "}\n",
    "$$\n",
    "\n",
    "Again, this is what Chris shows just with different element indices. Ok, so this is the answer we are looking for. Now let’s see what we get when we do the tf-idf calculation in ```sklearn```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.         1.40546511 1.        ]\n",
      " [0.         1.         0.         2.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Inverse document frequency (idf) feature extraction using sklearn\n",
    "# sklearn's TfidfTransformer is used to calculate the idf for each\n",
    "# term across all texts in test set. The default is to normalize all\n",
    "# idf values by the L2 norm. This normalization has been disabled by\n",
    "# passing the argument norm=None so that it is more intuitive to see\n",
    "# what is going on and can be compared to Chris' post.\n",
    "\n",
    "# import TfidfTransformer from sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# make instance of TfidfTransformer called \"tfidf\"\n",
    "\n",
    "tfidf = TfidfTransformer(norm=None)\n",
    "\n",
    "# return un-normalized tf-idf matrix using sparse matrix of tf values that\n",
    "# was generated above\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(smatrix)\n",
    "\n",
    "print(tfidf_matrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is quite different from what we expected. When stuff like this happens, I immediately go to the documentation page or stackoverflow (after first making sure that I didn’t make a mistake). **After some digging, I found out that the default equation for calculating the idf in sklearn is not the same as what is shown above!** The equation that sklearn uses is described [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html):\n",
    "\n",
    "> If ```smooth_idf=True``` (the default), the constant “1” is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions: idf(d, t) = log [ (1 + n) / (1 + df(d, t)) ] + 1.\n",
    "\n",
    "Now if we do this calculation using the formula above, we get the following:\n",
    "\n",
    "   >**Blue**: $ln ((1+2)/(1+0)) + 1 = 2.099$\n",
    "\n",
    "   >**Bright**: $ln ((1+2)/(1+2)) + 1= 1.0$\n",
    "\n",
    "   >**Sky**: $ln ((1+2)/(1+1)) + 1= 1.405$\n",
    "\n",
    "   >**Sun**: $ln ((1+2)/(1+2)) + 1 = 1.0$\n",
    "   \n",
    "The expected tf-idf would then be:\n",
    "\n",
    "$$\n",
    "\\large{\n",
    "\\begin{bmatrix} \n",
    "0 & 1 & 1.405 & 1 \\\\\n",
    "0 & 1 & 0 & 2 \n",
    "\\end{bmatrix}\n",
    "}\n",
    "$$\n",
    "\n",
    "Which is exactly what we saw!\n",
    "\n",
    "### So the moral of the story is…make sure you know which definition you are using!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
